import { Tokenizer } from "@mlc-ai/web-tokenizers";

/**
 * The class that streams back validated utf-8 text strings generated by the tokenizer. We need
 * such a buffering mechanism as decoding each token may not result in the same string when several
 * tokens are required to form the valid utf-8 text. Consider the case of emojis which compose of
 * 4 tokens.
 * 
 * The implementation follows that in https://github.com/mlc-ai/mlc-llm/blob/main/cpp/streamer.cc
 * The main difference is that in C++, the replacement character takes three characters.
 */
export class TextStreamer {
  private tokenizer: Tokenizer;
  private prefix_tokens: number[] = [];
  private pending_tokens: number[] = [];
  private finished = false;

  // REPLACEMENT CHARACTER (U+FFFD) in UTF-8.
  readonly kReplacementCharacter = "ï¿½";

  constructor(tokenizer: Tokenizer) {
    this.tokenizer = tokenizer;
  }

  /**
   * Put new delta tokens into the streamer, and get the UTF-8-valid delta string. The text streamer
   * may hold some of the input delta tokens which cannot decode into valid UTF-8 strings. The
   * returned string is always guaranteed to be UTF-8 valid.
   * @param delta_tokens The new tokens to put into the streamer.
   * @return The decoded delta string after putting the input new tokens, can be empty.
   */
  put(delta_tokens: number[]): string {
    if (this.finished) {
      throw Error("`put` is not expected to be invoked after finish.");
    }
    if (delta_tokens.length === 0) {
      return "";
    }

    let ret = "";
    // We process delta tokens one by one
    for (const delta_token of delta_tokens) {
      // push to pending tokens
      this.pending_tokens.push(delta_token);

      // all_tokens = this.prefix_tokens + this.pending_tokens
      const all_tokens: number[] = [];
      all_tokens.push(...this.prefix_tokens);
      all_tokens.push(...this.pending_tokens);

      // Decode this.prefix_tokens and all_tokens
      const prefix_str = this.prefix_tokens.length === 0 ?
        "" : this.tokenizer.decode(new Int32Array(this.prefix_tokens));
      let full_str = this.tokenizer.decode(new Int32Array(all_tokens));

      let validated_str: string;
      const new_pending_tokens: number[] = [];

      // console.log("=====================");
      // console.log("prefix_tokens: " + this.prefix_tokens);
      // console.log("pending_tokens: " + this.pending_tokens);
      // console.log("prefix_str: " + prefix_str);
      // console.log("full_str: " + full_str);

      if (full_str.startsWith(prefix_str)) {
        // console.log("CASE 1");
        // Case 1. prefix_str is a prefix of full_str.
        validated_str = full_str.substring(prefix_str.length);

        // Pop UTF-8 replacement character from the back of pending tokens.
        // - The UTF-8 replacement character take 3 chars.
        // - A valid UTF-8 has 4 chars at most.
        //   So there will be at most 3 tokens popped.
        // console.log("this.pending_tokens.length: " + this.pending_tokens.length);
        // console.log("new_pending_tokens.length: " + new_pending_tokens.length);
        // console.log("validated_str.length: " + validated_str.length);
        // console.log("validated_str.substring(validated_str.length - 1): " + validated_str.substring(validated_str.length - 1));
        // console.log("validated_str.substring(validated_str.length - 1) === this.kReplacementCharacter: ", validated_str.substring(validated_str.length - 1) === this.kReplacementCharacter);


        while (this.pending_tokens.length !== 0 &&
          new_pending_tokens.length < 3 &&
          validated_str.length >= 1 &&
          validated_str.substring(validated_str.length - 1) === this.kReplacementCharacter
        ) {
          // eslint-disable-next-line @typescript-eslint/no-non-null-assertion
          new_pending_tokens.push(this.pending_tokens.pop()!);
          validated_str = validated_str.substring(0, validated_str.length - 1);
          // console.log("validated_str: " + validated_str);
        }
      } else {
        // Case 2. prefix_str is not a prefix of `full_str`.
        // Pop pending tokens from the back.
        // - Pop until prefix_str is indeed a prefix of full_str.
        // - A valid UTF-8 has 4 chars at most.
        //   So there will be at most 3 tokens popped.
        // - If there are no more than 3 pending tokens, skip popping.
        //   This is because it is impossible to make full_str contain
        //   prefix_str without popping all the pending tokens.
        // console.log("CASE 2");
        if (this.pending_tokens.length < 3) {
          continue;
        }
        let get_valid_full_str = false;
        while (this.pending_tokens.length !== 0 && new_pending_tokens.length < 3) {
          // eslint-disable-next-line @typescript-eslint/no-non-null-assertion
          new_pending_tokens.push(this.pending_tokens.pop()!);
          all_tokens.pop();
          full_str = this.tokenizer.decode(new Int32Array(all_tokens));
          if (full_str.startsWith(prefix_str)) {
            get_valid_full_str = true;
            break;
          }
        }

        if (get_valid_full_str) {
          // We find a full_str which starts from prefix_str.
          // So we return the sliced full string without the prefix.
          validated_str = full_str.substring(prefix_str.length);
        } else {
          // We cannot find a full_str which starts from prefix_str by
          // popping 3 tokens.
          // In this case, the remaining pending tokens are invalid UTF-8
          // characters already, so we return the decoded pending tokens.
          validated_str = this.tokenizer.decode(new Int32Array(this.pending_tokens));
        }
      }

      if (this.pending_tokens.length !== 0) {
        // Set the new prefix
        this.prefix_tokens = [...this.pending_tokens];
      }
      this.pending_tokens = new_pending_tokens.reverse();
      ret += validated_str;
    }
    // console.log("prefix_tokens: " + this.prefix_tokens);
    // console.log("pending_tokens: " + this.pending_tokens);
    // console.log("ret: " + ret);
    return ret;
  }

  finish(): string {
    // all_tokens = this.prefix_tokens + this.pending_tokens
    const all_tokens: number[] = [];
    all_tokens.push(...this.prefix_tokens);
    all_tokens.push(...this.pending_tokens);

    // Decode this.prefix_tokens and all_tokens
    const prefix_str = this.prefix_tokens.length === 0 ?
      "" : this.tokenizer.decode(new Int32Array(this.prefix_tokens));
    const full_str = this.tokenizer.decode(new Int32Array(all_tokens));

    this.finished = true;
    if (full_str.startsWith(prefix_str)) {
      // Case 1. prefix_str is a prefix of `full_str`.
      return full_str.substring(prefix_str.length);
    } else {
      // Case 2. prefix_str is not a prefix of `full_str`.
      // In this case, the remaining pending tokens are invalid UTF-8
      // characters already, so we return the decoded pending tokens.
      return this.tokenizer.decode(new Int32Array(this.pending_tokens));
    }
  }
}
